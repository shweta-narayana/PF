#A scraper to pull data from  multiple pages
import requests
import lxml
from bs4 import BeautifulSoup

url='https://scrapingclub.com/exercise/list_basic/'

#read the html on the main page and build a list of urls to scrape
pages=soup.find('ul',class_='pagination')
urls=[]
links=pages.find_all('a',class_='page-link')
for i in links:
    pageNum=int(i.text) if i.text.isdigit() else None
    if pageNum!=None :
        urls.append(i.get('href'))

#loop through each page and find the item names and prices and display it
count=1
for i in urls:
    newurl=url+i
    print('Page:',newurl)
    response=requests.get(newurl)
    soup=BeautifulSoup(response.text,'lxml')
    items=soup.find_all('div',class_="col-lg-4 col-md-6 mb-4")
    
    for i in items:
        itemName=i.find('h4',class_='card-title').text.strip('\n')
        itemPrice=i.find('h5').text
        print(count,'Item Name:',itemName,'Price:',itemPrice)
        count=count+1
